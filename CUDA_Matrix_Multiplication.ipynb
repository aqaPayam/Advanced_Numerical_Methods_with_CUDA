{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3T2xnRX3M6yU"
      },
      "outputs": [],
      "source": [
        "name = 'Payam Taebi'\n",
        "student_number = '400104867'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import and load nvcc [using google colab]\n",
        "\n",
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0DHZYylNEbT",
        "outputId": "bc367d25-10b2-4103-a9f6-2d46bf282870"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-_yevsg4v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-_yevsg4v\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "directory /content/src already exists\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1)\n",
        " First, write this program in normal ++Ⅽ̸Ⅽ and calculate the execution time of the program in ⅭPU. If\n",
        "The dimensions of 10240 were too large and it took too long to run, so run your program in dimensions of 1024.\n",
        "But consider this issue in your next analysis.\n",
        "\n",
        "#2)\n",
        " Rewrite the program calculations in ⅭUⅮA. At this stage, you do not need to use GPU facilities such as memory shards."
      ],
      "metadata": {
        "id": "vtAUrhImNpjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "i set size 1024 * 1024 and implement MATRIX MULTIPICATION IN CPU and MATRIX MULTIPICATION IN CUDA USING GPU"
      ],
      "metadata": {
        "id": "Uov4kZRfPIue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_cpu_gpu.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <stdbool.h>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "int N = 1024;\n",
        "\n",
        "//implementing C = A * B with CPU\n",
        "void cpu_mult(int N, float *A, float *B, float *C) {\n",
        "    float sum_matrix = 0.0f;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            sum_matrix = 0.0f;\n",
        "            for (int k = 0; k < N; ++k) {\n",
        "                sum_matrix += A[N * i + k] * B[N * k + j];\n",
        "            }\n",
        "            C[N * i + j] = sum_matrix;\n",
        "            sum_matrix = 0.0f;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// now implementing CUDA mm using GPU\n",
        "__global__ void gpu_mult(int N, float *A, float *B, float *C) {\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float sum_matrix = 0.0f;\n",
        "    if (row < N && col < N) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum_matrix = sum_matrix + A[N * row + i] * B[N * i + col];\n",
        "        }\n",
        "        C[N * row + col] = sum_matrix;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[]) {\n",
        "\n",
        "    //size of matrix\n",
        "    int size = sizeof(float) * N * N;\n",
        "    int matrix_size = N * N;\n",
        "\n",
        "    // define Matrix\n",
        "    float *A;\n",
        "    float *B;\n",
        "    float *C_cpu;\n",
        "    float *C_gpu;\n",
        "\n",
        "    // allocate\n",
        "    cudaMallocHost((void **) &A, size);\n",
        "    cudaMallocHost((void **) &B, size);\n",
        "    cudaMallocHost((void **) &C_cpu, size);\n",
        "    cudaMallocHost((void **) &C_gpu, size);\n",
        "\n",
        "    for (int i = 0; i < matrix_size; ++i) {\n",
        "        A[i] = (float)rand() / RAND_MAX;\n",
        "        B[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // now variables initialized and we can calculate result with CPU and GPU\n",
        "\n",
        "    float gpu_time, cpu_time;\n",
        "\n",
        "    // initializing temp variables\n",
        "    float *tA;\n",
        "    float *tB;\n",
        "    float *tC;\n",
        "\n",
        "    cudaMalloc((void **) &tA, size);\n",
        "    cudaMalloc((void **) &tB, size);\n",
        "    cudaMalloc((void **) &tC, size);\n",
        "\n",
        "    // copy var Host to Device\n",
        "    cudaMemcpy(tA, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(tB, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    // use cudaEvent_t\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    // using cudaEventCreate to start the timing\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    // start the record with cudaEventRecord\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    unsigned int grid_rows = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    unsigned int grid_cols = grid_rows;\n",
        "\n",
        "\n",
        "    // using dm3 in cuda for:\n",
        "    // dim3 is an integer vector type based on uint3 that is used to specify dimensions.\n",
        "    // When defining a variable of type dim3, any component left unspecified is initialized to 1.\n",
        "    dim3 dimGrid(grid_cols, grid_rows);\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "    // calling gpu mult to start gpu for multiplication\n",
        "    gpu_mult<<<dimGrid, dimBlock>>> (N, tA, tB, tC);\n",
        "\n",
        "     // copy device to GPU\n",
        "    cudaMemcpy(C_gpu, tC, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // finish the record for knowing the time that took\n",
        "    cudaEventRecord(end, 0);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    // blocks execution until the specified event is recorded with cudaEventElapsedTime\n",
        "    cudaEventElapsedTime(&gpu_time, start, end);\n",
        "\n",
        "\n",
        "\n",
        "    // now run mult for CPU:\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    cpu_mult(N, A, B, C_cpu);\n",
        "\n",
        " // blocks execution until the specified event is recorded with cudaEventElapsedTime and save in cpu_time\n",
        "\n",
        "    cudaEventRecord(end, 0);\n",
        "    cudaEventSynchronize(end);\n",
        "    cudaEventElapsedTime(&cpu_time, start, end);\n",
        "\n",
        "    // print cpu_time\n",
        "    printf(\"Time on CPU: %f seconds\\n\", cpu_time / 1000);\n",
        "\n",
        "        // print gpu_time\n",
        "    printf(\"Time on GPU: %f seconds\\n\", gpu_time / 1000);\n",
        "\n",
        "    // finally, Memory free\n",
        "\n",
        "\n",
        "    cudaFreeHost(tA);\n",
        "    cudaFreeHost(tB);\n",
        "    cudaFreeHost(tC);\n",
        "\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C_gpu);\n",
        "    cudaFreeHost(C_cpu);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLaKXbpGNleq",
        "outputId": "264d4d6c-26b8-48ad-c890-93b7786738bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_cpu_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_mul_cpu_gpu.cu -o matrix_mul_cpu_gpu -lcurand\n",
        "!./matrix_mul_cpu_gpu"
      ],
      "metadata": {
        "id": "HY1EH2gVQs3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376bc34b-34b8-4ee0-f95a-e136c3b1053b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time on CPU: 8.565032 seconds\n",
            "Time on GPU: 0.009596 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3)\n",
        " Rewrite the previous program using shared memory. Check that the shared memory is approximately filled in the dimensions of the matrices."
      ],
      "metadata": {
        "id": "Nc-d7NDjM8zI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we have used shared memory to increase speed. With the help of \"shared\" , we have access to the shared memory. By doing this, the data is copied from the global memory to the shared memory in each block. In this way, the data is closer to the threads and the access time is reduced.\n",
        "But the result is not much better because we access the matrix elements in the same way as they are stored in the memory."
      ],
      "metadata": {
        "id": "0a5rKrTsNmg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_shared_memory.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <stdbool.h>\n",
        "\n",
        "#define BLOCK_SIZE 4\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void gpu_mult_shared(float *A, float *B, float *C) {\n",
        "    __shared__ float sA[BLOCK_SIZE][N];\n",
        "    __shared__ float sB[N][BLOCK_SIZE];\n",
        "\n",
        "    int row = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n",
        "\n",
        "    int e1;\n",
        "    int e2;\n",
        "    int t = N / BLOCK_SIZE;\n",
        "\n",
        "    for (int m = 0; m < t; m++) {\n",
        "        e1 = m * BLOCK_SIZE + threadIdx.x;\n",
        "        e2 = m * BLOCK_SIZE + threadIdx.y;\n",
        "        sA[threadIdx.y][e1] = A[N * row + e1];\n",
        "        sB[e2][threadIdx.x] = B[N * e2 + col];\n",
        "    }\n",
        "\n",
        "    float tmp = 0.0f;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int k = 0; k < N; ++k){\n",
        "        tmp += sA[threadIdx.y][k] * sB[k][threadIdx.x];\n",
        "    }\n",
        "    if (col < N && row < N) C[N * row + col] = tmp;\n",
        "}\n",
        "\n",
        "// like before\n",
        "__global__ void gpu_mult_not_shared(float *A, float *B, float *C) {\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float sum_matrix = 0.0f;\n",
        "    if (row < N && col < N) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum_matrix = sum_matrix + A[N * row + i] * B[N * i + col];\n",
        "        }\n",
        "        C[N * row + col] = sum_matrix;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char const *argv[]) {\n",
        "\n",
        "    //size of matrix\n",
        "    int size = sizeof(float) * N * N;\n",
        "    int matrix_size = N * N;\n",
        "\n",
        "    // define variables\n",
        "    float *A;\n",
        "    float *B;\n",
        "    float *C_ns;\n",
        "    float *C_s;\n",
        "\n",
        "    // allocate\n",
        "    cudaMallocHost((void **) &A, size);\n",
        "    cudaMallocHost((void **) &B, size);\n",
        "    cudaMallocHost((void **) &C_ns, size);\n",
        "    cudaMallocHost((void **) &C_s, size);\n",
        "\n",
        "    // filling matrix\n",
        "    for (int i = 0; i < matrix_size; ++i) {\n",
        "        A[i] = (float)rand() / RAND_MAX;\n",
        "        B[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "\n",
        "    float gpu_ns_time , gpu_s_time;\n",
        "\n",
        "    // use cudaEvent_t to know about that\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    // using cudaEventCreate to start the timing\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    // start the record with cudaEventRecord\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // define  temp variables\n",
        "    float *tA;\n",
        "    float *tB;\n",
        "    float *tC_ns;\n",
        "    float *tC_s;\n",
        "\n",
        "    // allocate\n",
        "    cudaMalloc((void **) &tA, size);\n",
        "    cudaMalloc((void **) &tB, size);\n",
        "    cudaMalloc((void **) &tC_ns, size);\n",
        "    cudaMalloc((void **) &tC_s, size);\n",
        "\n",
        "    // copy var Host to Device\n",
        "    cudaMemcpy(tA, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(tB, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    unsigned int grid_rows = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    unsigned int grid_cols = grid_rows;\n",
        "\n",
        "    // using dm3 in cuda for:\n",
        "    // dim3 is an integer vector type based on uint3 that is used to specify dimensions.\n",
        "    // When defining a variable of type dim3, any component left unspecified is initialized to 1.\n",
        "    dim3 dimGrid(grid_cols, grid_rows);\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "    // calling gpu_mm to start gpu for multiplication\n",
        "    gpu_mult_not_shared<<<dimGrid, dimBlock>>> (tA, tB, tC_ns);\n",
        "\n",
        "    // copy device to GPU\n",
        "    cudaMemcpy(C_ns, tC_ns, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // finish the record for knowing the time that took\n",
        "    cudaEventRecord(end, 0);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    // blocks execution until the specified event is recorded with cudaEventElapsedTime\n",
        "    cudaEventElapsedTime(&gpu_ns_time, start, end);\n",
        "\n",
        "\n",
        "    // So far, we have not done anything new and implemented the GPU as in the previous section, and from here on, we will focus on the shared memory section\n",
        "\n",
        "    // start another start timing:\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    gpu_mult_shared<<<dimGrid, dimBlock>>> (tA, tB, tC_s);\n",
        "\n",
        "// blocks execution until the specified event is recorded with cudaEventElapsedTime and save in gpu_s_time\n",
        "\n",
        "    cudaEventRecord(end, 0);\n",
        "    cudaEventSynchronize(end);\n",
        "    cudaEventElapsedTime(&gpu_s_time, start, end);\n",
        "\n",
        "    // print gpu_s_time\n",
        "    printf(\"Time on GPU, shared: %f seconds\\n\", gpu_s_time / 1000);\n",
        "\n",
        "    // print gpu_time\n",
        "    printf(\"Time on GPU, not shared: %f seconds \\n\", gpu_ns_time / 1000);\n",
        "\n",
        "\n",
        "    // free memory\n",
        "    cudaFree(tA);\n",
        "    cudaFree(tB);\n",
        "    cudaFree(tC_ns);\n",
        "    cudaFree(tC_s);\n",
        "\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C_ns);\n",
        "    cudaFreeHost(C_s);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM1_e555MXO3",
        "outputId": "5cf9d620-cfa1-4278-ab6f-ca7521ab7e2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_shared_memory.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_mul_shared_memory.cu -o matrix_mul_shared_memory -lcurand\n",
        "!./matrix_mul_shared_memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrhybhFaM3ZF",
        "outputId": "7fb1dcac-85eb-4e6f-e8f7-65d4a4f44fb6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time on GPU, shared: 0.037522 seconds\n",
            "Time on GPU, not shared: 0.030857 seconds \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4)\n",
        "Research the tiling technique. Improve your previous program by using tiling and explain why this program performs better than the previous program."
      ],
      "metadata": {
        "id": "zZ-PilqsmyAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we use tiling. In this method, we divide the matrix into two tiles and calculate each tile separately. It divides the long access sequence of each thread into phases and uses barrier synchronization to keep the access time of each segment in close time intervals. This technique controls the amount of on-chip memory required by localizing accesses in time and space."
      ],
      "metadata": {
        "id": "r7AGWSJ_oIZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tiling.cu\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <stdbool.h>\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "int N = 10240;\n",
        "\n",
        "__global__ void gpu_mult_shared(int N, float *A, float *B, float *C) {\n",
        "    __shared__ float tA[BLOCK_SIZE][BLOCK_SIZE];\n",
        "    __shared__ float tB[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float tmp = 0.0f;\n",
        "\n",
        "    int m;\n",
        "    for (int sub = 0; sub < gridDim.x; sub++) {\n",
        "        m = row * N + sub * BLOCK_SIZE;\n",
        "\n",
        "        if (N % BLOCK_SIZE != 0)\n",
        "            tA[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "        else\n",
        "            tA[threadIdx.y][threadIdx.x] = A[m];\n",
        "\n",
        "        m = (sub * BLOCK_SIZE + threadIdx.y) * N + col;\n",
        "\n",
        "        if (N % BLOCK_SIZE != 0)\n",
        "            tB[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "        else\n",
        "            tB[threadIdx.y][threadIdx.x] = B[m];\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
        "            tmp += tA[threadIdx.y][k] * tB[k][threadIdx.x];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (col < N && row < N) C[N * row + col] = tmp;\n",
        "}\n",
        "\n",
        "__global__ void gpu_mult_not_shared(int N, float *A, float *B, float *C) {\n",
        "    // like always:\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // A * B = C --> more details in report\n",
        "    float sum_matrix = 0.0f;\n",
        "    if (row < N && col < N) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum_matrix = sum_matrix + A[N * row + i] * B[N * i + col];\n",
        "        }\n",
        "        C[N * row + col] = sum_matrix;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char const *argv[]) {\n",
        "\n",
        "\n",
        "\n",
        "    //size of matrix\n",
        "    int size = sizeof(float) * N * N;\n",
        "    int matrix_size = N * N;\n",
        "\n",
        "    // define variables\n",
        "    float *A;\n",
        "    float *B;\n",
        "    float *C_ns;\n",
        "    float *C_s;\n",
        "\n",
        "    // allocate\n",
        "    cudaMallocHost((void **) &A, size);\n",
        "    cudaMallocHost((void **) &B, size);\n",
        "    cudaMallocHost((void **) &C_ns, size);\n",
        "    cudaMallocHost((void **) &C_s, size);\n",
        "\n",
        "    // filling matrix\n",
        "    for (int i = 0; i < matrix_size; ++i) {\n",
        "        A[i] = (float)rand() / RAND_MAX;\n",
        "        B[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "\n",
        "    float gpu_ns_time , gpu_s_time;\n",
        "\n",
        "    // use cudaEvent_t to know about that\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    // using cudaEventCreate to start the timing\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    // start the record with cudaEventRecord\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // define variables\n",
        "    float *tA;\n",
        "    float *tB;\n",
        "    float *tC_ns;\n",
        "    float *tC_s;\n",
        "\n",
        "    // allocate\n",
        "    cudaMalloc((void **) &tA, size);\n",
        "    cudaMalloc((void **) &tB, size);\n",
        "    cudaMalloc((void **) &tC_ns, size);\n",
        "    cudaMalloc((void **) &tC_s, size);\n",
        "\n",
        "    // copy var Host to Device\n",
        "    cudaMemcpy(tA, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(tB, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    unsigned int grid_rows = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    unsigned int grid_cols = grid_rows;\n",
        "\n",
        "    // using dm3 in cuda for:\n",
        "    // dim3 is an integer vector type based on uint3 that is used to specify dimensions.\n",
        "    // When defining a variable of type dim3, any component left unspecified is initialized to 1.\n",
        "    dim3 dimGrid(grid_cols, grid_rows);\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "    // calling gpu_mm to start gpu for multiplication\n",
        "\n",
        "    gpu_mult_not_shared<<<dimGrid, dimBlock>>> (N, tA, tB, tC_ns);\n",
        "\n",
        "    // copy device to GPU\n",
        "    cudaMemcpy(C_ns, tC_ns, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // finish the record for knowing the time that took\n",
        "    cudaEventRecord(end, 0);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    // blocks execution until the specified event is recorded with cudaEventElapsedTime\n",
        "    cudaEventElapsedTime(&gpu_ns_time, start, end);\n",
        "\n",
        "\n",
        "\n",
        "    //start cpu and start timing:\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // calling the function\n",
        "    gpu_mult_shared<<<dimGrid, dimBlock>>> (N, tA, tB, tC_s);\n",
        "\n",
        "\n",
        " // blocks execution until the specified event is recorded with cudaEventElapsedTime and save in gpu_s_time\n",
        "\n",
        "    cudaEventRecord(end, 0);\n",
        "    cudaEventSynchronize(end);\n",
        "    cudaEventElapsedTime(&gpu_s_time, start, end);\n",
        "\n",
        "    printf(\"for n = %d :\\n\",N);\n",
        "\n",
        "    // print shared\n",
        "    printf(\"Time on GPU, shared: %f seconds\\n\", gpu_s_time / 1000);\n",
        "\n",
        "    // print not shared\n",
        "    printf(\"Time on GPU, not shared: %f seconds\\n\", gpu_ns_time / 1000 );\n",
        "\n",
        "    cudaFree(tA);\n",
        "    cudaFree(tB);\n",
        "    cudaFree(tC_ns);\n",
        "    cudaFree(tC_s);\n",
        "\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C_ns);\n",
        "    cudaFreeHost(C_s);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "wmdgmro6ODrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c916cace-b169-485c-f245-2958a1c4bf6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tiling.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc tiling.cu -o tiling -lcurand\n",
        "!./tiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvtK0iSnoVFA",
        "outputId": "ef917043-2e77-4a86-85f3-a4ec8df65e35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for n = 10240 :\n",
            "Time on GPU, shared: 2.361471 seconds\n",
            "Time on GPU, not shared: 3.722106 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5)\n",
        "Research memory coalescing on GPU. Now which LOAD commands in your program use MEMORY COALESCING and which ones don't? What method do you suggest for using MEMORY COALESCING in these commands? Implement it and report the implementation OVERHEAD as well as the resulting performance improvement."
      ],
      "metadata": {
        "id": "_jwW4yspqQVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing matrices as a contiguous n * n array takes advantage of the computer's architecture, as reading an element of the matrix will also make its row neighbors accessible in the cache. Generally, reading a row is much faster than reading a column. In the program, whenever we read elements of the first matrix, we are actually using memory coalescing because we are reading from the row.\n",
        "\n",
        "Now, in order to use this method for reading columns as well and make the calculations faster, we need to transpose the second matrix. This way, to calculate the element i,j, we will need to multiply row i of the first matrix with row j of the transposed second matrix. I have implemented this change in the multiplication using shared memory, but naturally, there is an additional overhead for calculating the transpose of the matrix."
      ],
      "metadata": {
        "id": "HDyN_e4chbja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mult_transpose.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <stdbool.h>\n",
        "\n",
        "#define BLOCK_SIZE 4\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void gpu_transpose(float *input, float *output) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    output[x * N + y] = input[y * N + x];\n",
        "}\n",
        "\n",
        "__global__ void gpu_mult_shared_transpose(float *A, float *B, float *C) {\n",
        "\n",
        "    __shared__ float sA[BLOCK_SIZE][N];\n",
        "    __shared__ float sB[BLOCK_SIZE][N];\n",
        "\n",
        "    int row = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n",
        "\n",
        "    int e1;\n",
        "    int e2;\n",
        "    int t = N / BLOCK_SIZE;\n",
        "\n",
        "    for (int m = 0; m < t; m++) {\n",
        "        e1 = m * BLOCK_SIZE + threadIdx.x;\n",
        "        e2 = m * BLOCK_SIZE + threadIdx.y;\n",
        "        sA[threadIdx.y][e1] = A[N * row + e1];\n",
        "        sB[threadIdx.x][e2] = B[N * col + e2];\n",
        "    }\n",
        "\n",
        "    float tmp = 0.0f;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int k = 0; k < N; ++k){\n",
        "        tmp += sA[threadIdx.y][k] * sB[threadIdx.x][k];\n",
        "    }\n",
        "    if (col < N && row < N) C[N * row + col] = tmp;\n",
        "}\n",
        "\n",
        "// like before\n",
        "__global__ void gpu_mult_not_shared(float *A, float *B, float *C) {\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float sum_matrix = 0.0f;\n",
        "    if (row < N && col < N) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum_matrix = sum_matrix + A[N * row + i] * B[N * i + col];\n",
        "        }\n",
        "        C[N * row + col] = sum_matrix;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char const *argv[]) {\n",
        "\n",
        "    //size of matrix\n",
        "    int size = sizeof(float) * N * N;\n",
        "    int matrix_size = N * N;\n",
        "\n",
        "    // define variables\n",
        "    float *A;\n",
        "    float *B;\n",
        "    float *C_ns;\n",
        "    float *C_s;\n",
        "\n",
        "    // allocate\n",
        "    cudaMallocHost((void **) &A, size);\n",
        "    cudaMallocHost((void **) &B, size);\n",
        "    cudaMallocHost((void **) &C_ns, size);\n",
        "    cudaMallocHost((void **) &C_s, size);\n",
        "\n",
        "    // filling matrix\n",
        "    for (int i = 0; i < matrix_size; ++i) {\n",
        "        A[i] = (float)rand() / RAND_MAX;\n",
        "        B[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "\n",
        "    float gpu_ns_time , gpu_s_time;\n",
        "\n",
        "    // use cudaEvent_t to know about that\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    // using cudaEventCreate to start the timing\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    // start the record with cudaEventRecord\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // define  temp variables\n",
        "    float *tA;\n",
        "    float *tB;\n",
        "    float *tBT;\n",
        "    float *tC_ns;\n",
        "    float *tC_s;\n",
        "\n",
        "    // allocate\n",
        "    cudaMalloc((void **) &tA, size);\n",
        "    cudaMalloc((void **) &tB, size);\n",
        "    cudaMalloc((void **) &tBT, size);\n",
        "    cudaMalloc((void **) &tC_ns, size);\n",
        "    cudaMalloc((void **) &tC_s, size);\n",
        "\n",
        "    // copy var Host to Device\n",
        "    cudaMemcpy(tA, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(tB, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    unsigned int grid_rows = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    unsigned int grid_cols = grid_rows;\n",
        "\n",
        "    // using dm3 in cuda for:\n",
        "    // dim3 is an integer vector type based on uint3 that is used to specify dimensions.\n",
        "    // When defining a variable of type dim3, any component left unspecified is initialized to 1.\n",
        "    dim3 dimGrid(grid_cols, grid_rows);\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "    //calculate gpu B_transpose\n",
        "    gpu_transpose<<<dimGrid, dimBlock>>>(tB, tBT);\n",
        "\n",
        "    // calling gpu_mm to start gpu for multiplication\n",
        "    gpu_mult_not_shared<<<dimGrid, dimBlock>>> (tA, tB, tC_ns);\n",
        "\n",
        "    // copy device to GPU\n",
        "    cudaMemcpy(C_ns, tC_ns, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // finish the record for knowing the time that took\n",
        "    cudaEventRecord(end, 0);\n",
        "\n",
        "    // Synchronize\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    // blocks execution until the specified event is recorded with cudaEventElapsedTime\n",
        "    cudaEventElapsedTime(&gpu_ns_time, start, end);\n",
        "\n",
        "\n",
        "    // So far, we have not done anything new and implemented the GPU as in the previous section, and from here on, we will focus on the shared memory section\n",
        "\n",
        "    // start another start timing:\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    gpu_mult_shared_transpose<<<dimGrid, dimBlock>>> (tA, tBT, tC_s);\n",
        "\n",
        "// blocks execution until the specified event is recorded with cudaEventElapsedTime and save in gpu_s_time\n",
        "\n",
        "    cudaEventRecord(end, 0);\n",
        "    cudaEventSynchronize(end);\n",
        "    cudaEventElapsedTime(&gpu_s_time, start, end);\n",
        "\n",
        "    // print gpu_s_time\n",
        "    printf(\"Time on GPU, shared using B^T instead of B: %f seconds\\n\", gpu_s_time / 1000);\n",
        "\n",
        "    // print gpu_time\n",
        "    printf(\"Time on GPU, not shared: %f seconds \\n\", gpu_ns_time / 1000);\n",
        "\n",
        "\n",
        "    // free memory\n",
        "    cudaFree(tA);\n",
        "    cudaFree(tB);\n",
        "    cudaFree(tC_ns);\n",
        "    cudaFree(tC_s);\n",
        "\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C_ns);\n",
        "    cudaFreeHost(C_s);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "qP8SoZsGp480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4187c6-10ac-4d00-973d-51a3af73ddf0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mult_transpose.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc mult_transpose.cu -o mult_transpose -lcurand\n",
        "!./mult_transpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjdR93KmrVnj",
        "outputId": "50464796-8467-428e-a2f8-b32f07453bae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time on GPU, shared using B^T instead of B: 0.040667 seconds\n",
            "Time on GPU, not shared: 0.031029 seconds \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUHE_IJLrYrL"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}